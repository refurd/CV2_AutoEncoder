{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder megvalósítása PyTorch-val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebben a notebook-ban megismerjük és implementálunk auto-encoder-eket. Egy vázlatos rajza az auto-encoder-nek az alábbi ábrán látható."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autoencoder](https://drive.google.com/uc?export=download&id=10sZv98I38nAKqhyVtZPHkmCeeNPgKn6r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Egy auto-encoder három részből áll:\n",
    "\n",
    "1. encoder (magasabb dimenziós bemenet -(tömörítés)- alacsonyabb dimenzió)\n",
    "2. encoded layer (látens vektor, bottleneck) \n",
    "3. decoder (alacsonyabb dimenzió -(kitömörítés)- magasabb dimenziós kimenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A leginkább számontartott AE variánsok, amikből mi is megtekintünk kettőt:\n",
    "\n",
    "* basic autoencoder\n",
    "* sparse autoencoder\n",
    "* contractive autoencoder\n",
    "* denoising autoencoder\n",
    "* variational autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referenciák: \n",
    "\n",
    "[Contractive autoencoder](http://www.icml-2011.org/papers/455_icmlpaper.pdf) </br>\n",
    "[Variational autoencoder](https://arxiv.org/pdf/1606.05908.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementáció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Először a CAE-t implementáljuk. A Frobenius-normát kézzel számoljuk egy adott architektúrára. Másodiknak a VAE-t készítjük el. A CAE egy példa diszkriminatív modellre, míg a VAE egy példa generatív modellre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pckutils import mnist, utils\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST példa, CAE és VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST adat beolvasása."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist.load_mnist('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fekete-fehér (bináris) kép generálása a szürke árnyalatos képből\n",
    "# trainloader készítése\n",
    "x_binary = utils.create_binary_image(data.X_train) \n",
    "X = torch.Tensor(x_binary)\n",
    "tensors = TensorDataset(X)\n",
    "trainloader = DataLoader(tensors, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elsőként a kontraktív AE-t készítjük el. A pytorch rendelkezik autogradiens modullal, de az a jelen esetben a nagy látens tér miatt hajlamos lassú és memória igényes lenni, ezért inkább kézzel számoljuk a deriváltat. A lassúság abból adódik, hogy túl nagy lesz a visszaterjesztés során a számítási fa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTautoencoderCAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_f, out_f):\n",
    "        super(MNISTautoencoderCAE, self).__init__()\n",
    "        self.in_f = in_f\n",
    "        self.out_f = out_f\n",
    "        \n",
    "        self.lin_enc = nn.Linear(in_f, out_f)\n",
    "        self.lin_dec = nn.Linear(out_f, in_f)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x - batch_size x in_f\n",
    "        '''\n",
    "        y_encoded = torch.sigmoid(self.lin_enc(x))\n",
    "        self.ae_reg = self.jacobi_loss_calc(y_encoded)\n",
    "        y_out = torch.sigmoid(self.lin_dec(y_encoded))\n",
    "        return y_out\n",
    "    \n",
    "    def jacobi_loss_calc(self, y):\n",
    "        sigmoid_der = y * (1-y)\n",
    "        w = list(self.lin_enc.parameters())[0]\n",
    "        sigmoid_der_2 = sigmoid_der**2\n",
    "        w_2 = w**2\n",
    "        return torch.sum(torch.matmul(sigmoid_der_2, w_2))\n",
    "    \n",
    "    def generate_image(self):\n",
    "        x_random = torch.rand(self.out_f)\n",
    "        return torch.sigmoid(self.lin_dec(x_random))\n",
    "    \n",
    "    def generate_image_from_random(self, x_random):\n",
    "        return torch.sigmoid(self.lin_dec(x_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segédfüggvény az AE tanításához\n",
    "def train_ae(ae, trainloader, lr, beta, device):\n",
    "    ae.device = device\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "    running_loss_reg = 0.0\n",
    "    running_loss_rec = 0.0\n",
    "    cntr = 0\n",
    "    \n",
    "    start = time.process_time()\n",
    "    for epoch in range(10):\n",
    "        for i, batch in enumerate(trainloader, 1):\n",
    "            cntr += 1\n",
    "            \n",
    "            optimizer.zero_grad()  # enélkül a gradiensek akkumulálódnak és a tanítás lelassulhat\n",
    "            x = batch[0]\n",
    "            x = x.to(device)\n",
    "        \n",
    "            y = ae(x)\n",
    "            loss_reg = beta * ae.ae_reg\n",
    "            loss_rec = criterion(y, x)\n",
    "            loss = loss_reg + loss_rec\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss_reg += loss_reg.item()\n",
    "            running_loss_rec += loss_rec.item()\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print('[%3d, %3d] loss_reg: %.3f  loss_rec: %.3f' %\n",
    "                (epoch + 1, i, running_loss_reg / 200, running_loss_rec / 200))\n",
    "            running_loss_reg = 0.0\n",
    "            running_loss_rec = 0.0\n",
    "    end = time.process_time()\n",
    "\n",
    "    print(\"Ellapsed time: %.5f\" %(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanítás az MNIST-en, majd megnézzük a helyreállítás minőségét."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ae = MNISTautoencoderCAE(784, 400).to(device)\n",
    "train_ae(ae, trainloader, 1e-3, 5e-4, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = utils.create_binary_image([data.X_test[15]])\n",
    "y = ae(torch.tensor(x_test[0]).view(1, -1).to(device))\n",
    "\n",
    "# eredeti\n",
    "plt.imshow(x_test[0].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helyreállított\n",
    "plt.imshow(y.detach().numpy().reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTautoencoderVAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_in, feature_out):\n",
    "        super(MNISTautoencoderVAE, self).__init__()\n",
    "        self.feature_in = feature_in\n",
    "        self.feature_out = feature_out\n",
    "        \n",
    "        self.lin_enc1 = nn.Linear(feature_in, 600)\n",
    "        self.lin_enc2 = nn.Linear(600, 500)\n",
    "        self.lin_enc_mu = nn.Linear(500, feature_out)\n",
    "        self.lin_enc_std = nn.Linear(500, feature_out)\n",
    "        \n",
    "        self.lin_dec1 = nn.Linear(feature_out, 500)\n",
    "        self.lin_dec2 = nn.Linear(500, 600)\n",
    "        self.lin_dec3 = nn.Linear(600, feature_in)\n",
    "        \n",
    "        self.ae_reg = 0.0\n",
    "        self.device = 0.0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder \n",
    "        x_ = torch.relu(self.lin_enc1(x))\n",
    "        x_ = torch.relu(self.lin_enc2(x_))\n",
    "        mu = torch.tanh(self.lin_enc_mu(x_)) # mean\n",
    "        std = torch.relu(self.lin_enc_std(x_)) + 1e-8 # standard deviation\n",
    "        samples = torch.normal(torch.zeros(mu.size(0), self.feature_out), torch.ones(mu.size(0), self.feature_out)).to(self.device)\n",
    "        self.u = mu + std * samples # reparametrization trick\n",
    "        \n",
    "        # regularizáció\n",
    "        self.ae_reg = self.calculate_reg(mu, std)\n",
    "        \n",
    "        # decoder\n",
    "        y_ = torch.relu(self.lin_dec1(self.u))\n",
    "        y_ = torch.relu(self.lin_dec2(y_))\n",
    "        return torch.sigmoid(self.lin_dec3(y_))\n",
    "    \n",
    "    def calculate_reg(self, mu, std):\n",
    "        kl_div = 0.5 * (std*std + mu*mu - 1.0 - torch.log(std*std))\n",
    "        return kl_div.sum()/mu.size(0) # devide by the batch_size\n",
    "    \n",
    "    def generate_image(self):\n",
    "        x_random = torch.normal(torch.zeros(self.feature_out), torch.ones(self.feature_out)).to(self.device)\n",
    "        y_ = torch.relu(self.lin_dec1(x_random))\n",
    "        y_ = torch.relu(self.lin_dec2(y_))\n",
    "        return torch.sigmoid(self.lin_dec3(y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reparametrization trick-hez minden mintához új elemet generálunk a standard normális eloszlásból. Nem elég az egész batch-re egy értéket generálni, mert akkor a tanulás sebesége nagyon lassú lesz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE tanítása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "mae = MNISTautoencoderVAE(28*28, 400).to(device)\n",
    "mae.device = device\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(mae.parameters(), lr=1e-3)\n",
    "running_loss_reg = 0.0\n",
    "running_loss_rec = 0.0\n",
    "cntr = 0\n",
    "\n",
    "for epoch in range(60):\n",
    "    for i, batch in enumerate(trainloader, 1):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = batch[0]\n",
    "        x = x.to(device)\n",
    "        \n",
    "        y = mae(x)\n",
    "        loss_reg = 5e-4*mae.ae_reg\n",
    "        loss_rec = criterion(y, x)\n",
    "        loss = loss_reg + loss_rec\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss_reg += loss_reg.item()\n",
    "        running_loss_rec += loss_rec.item()\n",
    "        cntr += 1\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('[%3d, %3d] loss_reg: %.3f  loss_rec: %.3f' %\n",
    "            (epoch + 1, i, running_loss_reg / cntr, running_loss_rec / cntr))\n",
    "        running_loss_reg = 0.0\n",
    "        running_loss_rec = 0.0\n",
    "        cntr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# súlyok mentése\n",
    "weights = list(map(lambda x: x.cpu().detach().numpy(), mae.parameters()))\n",
    "utils.save_parameters(weights, \"weights/Autoencoder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visszatöltés (ne kelljen újra tanítani a teszteléshez később)\n",
    "weights = utils.load_parameters(\"weights/Autoencoder.json\")\n",
    "mae = MNISTautoencoderCAE(28*28, 400)\n",
    "pms = list(map(torch.from_numpy, weights))\n",
    "\n",
    "for i, p in enumerate(mae.parameters()):\n",
    "    p.data = pms[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bemenet és kimenet vizuális ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = utils.create_binary_image([data.X_test[12]])\n",
    "y = mae(torch.tensor(x_test[0]).view(1, -1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.cpu().detach().numpy().reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mae.generate_image()\n",
    "plt.imshow(img.cpu().detach().numpy().reshape((28, 28)), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
